{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "Pandas is a Python package for the IO, analysis and handling of tables. If you are used to using Excel and want to use Python for analysis, Pandas is your friend. You can import it by just typing `import pandas`. However, it is so often used, it has even acquired a common alias in the Python community: `pd`. You can alias a package upon importing like so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> TODO: ensure pandas, seaborn are installed in the current environment. Follow same method as Day 2 (once uploaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # import pandas, and rename the package to \"pd\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"basic-pandas-functionality\"></a>\n",
    "### 1.1 Basic pandas functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will learn basic functionality of pandas.\n",
    "\n",
    "The core functionality of pandas is based on two primary data structures: `Series` and `DataFrames`.\n",
    "\n",
    "We will start by creating a simple DataFrame from scratch. pandas uses the concept of `DataFrame` instead of a \"table\" or \"spreadsheet\", as a `DataFrame` can be more general. However, it's ok to just think of it as a Python version of a spreadsheet.\n",
    "\n",
    "Although pandas is really built around the `DataFrame` data structure, you will also often come across `Series`. These are very similar to one-dimensional lists, but have the added benefit of having access to most of the same methods as `DataFrames`, and work very well with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_table = pd.DataFrame({\n",
    "    \"A\": [1, 2, 3, 4, 5],\n",
    "    \"B\": ['a', 'b', 'c', 'b', 'e'],\n",
    "    \"C\": [4.0, 5.0, 6.0, 7.0, 4.0],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by taking a look at our newly-initialized data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table.columns  # the labels of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table.index  # the index labels of each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table.shape  # the size of the DataFrame. Little bit silly here, but useful when they get larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oftentimes, tables/DataFrames are very big, and simply printing them out would take up most of your screen or more. You can quickly peek into a large dataframe using either `head()` or `tail()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table.head(n=2)  # show the first n rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table.tail(n=2)  # show the last n rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often useful to get some quick statistics of a table you have. `pandas` has a neat built-in method called `describe()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Question*: Why is column 'B' absent here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, we will want to flip our `DataFrame` on its head (or rather, diagonal). We can do that simply by using `.T`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, this swaps the column and index labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Columns: {my_table.T.columns}')\n",
    "print(f'Indices: {my_table.T.index}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Accessing data in the DataFrame\n",
    "\n",
    "There are many ways to access and set data in a pandas DataFrame. We will cover the default `pandas`-like way, but you may find other ways that seem more intuitive for you, or encounter different methods on the wild west of the world wide web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One nice feature to `pandas` that makes it more versatile than basic data structures and `numpy` arrays is that it allows us to not only use integer-based indexing; we can add our own labels to the indices. Let's say for instance that it somehow makes sense to add dates for each row (perhaps we are collecting this data once per day):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(\"20240503\", periods=5)\n",
    "my_table.set_index(dates, inplace=True)\n",
    "my_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a date associated with each row, we can easily \"query\" our dataset to look at our data corresponding to a particular day using `.loc` and square brackets around the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table.loc['2024-05-05']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to select data based on integer indexing, just like the data types we've seen so far. To do this, you need to use the `.iloc` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting a single _column_ from the Dataframe is even easier: simply use the index method of square brackets `[ ]` surrounding the column label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table['B']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access multiple columns at the same time, you can pass a list of the columns you want inside of the square brackets. This will result in double square brackets: `[[ ]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table[['A', 'B']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tuple of column names works equally well though, if that's what you prefer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you remember index slicing in numpy (see the lectures of the preivous day), then you might be happy to know that this also works for `pandas`! yay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table.iloc[:, 0:2]  # Only the first two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table.iloc[1:3, :]  # The second and third rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Querying data\n",
    "\n",
    "`pandas` is made to mimic SQL (a popular data-handling language) syntax. it allows you to quickly fetch data from big datasets based on indexing and applying different conditions. For example, say we want all data that is larger than some value in a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table[my_table['A'] > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or perhaps only the rows containing the letters 'a' or 'b' in column `'B'` should be returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table[my_table['B'].isin(['a', 'b'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use boolean masks too! For example, the `between()` function checks if a value in a row or column is between two other values. if this is the case, it returns `True`, otherwise `False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table['C'].between(3.5, 4.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this so-called boolean mask as an index, leading to relatively readable syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table[my_table['C'].between(3.5, 4.5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good way to read this code in English is: \"`my_table`, at the positions where `my_table` at column `'C'` is between $3.5$ and $4.5$\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it's almost always possible to access the data using an explicit \"vectorized\" form as shown in the three examples above, sometimes it's also useful to iterate through each row like we would in a list or even occasionally a `NumPy` array. For instance, this can help when plotting data as we will do later in this notebook. `my_table.iterrows()` will return an iterable object that we can use to access each row of our `DataFrame` at a time. The ins and outs of this don't particularly matter for our purposes, but this hopefully provides some intuition for the syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(my_table.columns))\n",
    "for index, row in my_table.iterrows():\n",
    "    if row['A'] > 2:\n",
    "        print(index)\n",
    "        print(list(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only is this less pretty, this method also doesn't allow us to modify the variables within. However, since it has its uses and is likely to be encountered in the future, we've decided to include it here.\n",
    "\n",
    "Now, try your hand at producing iterable versions of the other two examples from above in the next two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in my_table.iterrows():\n",
    "    # your code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in my_table.iterrows():\n",
    "    # your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Manipulating data\n",
    "\n",
    "So far, we've looked at how to construct `DataFrames` and some ways to analyze the data stored inside them. It is often the case that we'll also want to add or modify data within one of these data structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add data to our DataFrame: if our rows correspond to some measurement we've made across days, perhaps we've collected more today:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note: nothing we've done with our dataset so far has actually modified it as of yet. In the case where something happens to your table, simply run the first code cell in the [basic pandas functionality](#basic-pandas-functionality) section, followed by the necessary lines below, in order to get the data caught up again. Ask a TA if you need more help!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_observation = pd.DataFrame([[6, 'f', 1.5]], columns=['A', 'B', 'C'], index=pd.DatetimeIndex(['2024-05-08']))\n",
    "my_table = pd.concat((my_table, new_observation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(As is often the case with `pandas`, there are many, _many_ ways to add rows to `DataFrames`. This method is sufficient for our purposes since it allows us to also provide index labels to the newly-added row.)\n",
    "\n",
    "Let's take a glimpse again to make sure everything looks the way we expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we've done some important, complex analysis based on the relationship of two of our variables in our dataset: we multiply column `'A'` with column `'C'`, and we name this analysis `'D'`.\n",
    "\n",
    "Here, we can finally introduce the `Series` data structure. It would be fair to compare a `Series` to a single column of a `DataFrame`, as it must be one-dimensional, and the elements within a `Series` must all be the same data type (integer, string, boolean, float, etc.).\n",
    "\n",
    "This is perfect for our current situation then: let's create a `Series` based on calculations from our current data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_measurement = pd.Series(my_table['A'] * my_table['C'], name='D')\n",
    "new_measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...And add it to our `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table['D'] = new_measurement\n",
    "my_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy! Now, let's say that we recognize some data as an outlier, which we no longer want to keep in our dataset. We can remove data like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_table.drop('2024-05-06')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: we haven't actually removed the data point, but rather returned a copy of the data without the rows matching the specified index. Many times it's best to keep data and to just ignore it using some query, rather than removing it altogether. However, in the case where it's preferable to remove the data altogether, we can adjust the previous line in one of two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_table = my_table.drop('2024-05-09')\n",
    "# my_table.drop('2024-05-09', in_place=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: How might we do the same operation with a concrete definition of an outlier? Perhaps we would like to ignore any row where the value in `'D'` is greater than 25.0. Try this out for yourself in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation data\n",
    "\n",
    "The previous example used a rather simple dataset. Let's apply our freshly gained knowledge on something cooler. Below, you will learn how to read in and analyze a large `DataFrame` with simulation data. What this `DatFrame` actually contains should become more and more clear as the exercise progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_data = pd.read_csv('./data/simulation_data.csv', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that's a lot of columns... If we were to use `.describe()` right now, it would calculate statistics for each of 48 thousand columns. That might take some time. It would be wise to calculate some statistics of just a subset of this data to get a feeling. Let's use slicing to describe only the first handful of columns. This omits a lot of data, but at least we get a feeling of what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_data.iloc[:, :5].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmmmm, all of these values look kind of similar. The mean is $-76$, and so are the quartiles, min and max. Of column 0. Why could that be? \n",
    "\n",
    "> **Question**: What does this value represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of calculating statistics column per column, let's try to go row by row. We can ignore the `recording_location` column for this in the meantime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_data.drop(\"recording_location\", axis=1).T.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "sns.heatmap(\n",
    "    simulation_data.drop(['recording_location'], axis=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: What do you think this data is?\n",
    ">\n",
    ">**Question 2**: What could the x-axis be? What is the colorscale?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_data['recording_location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma = simulation_data[simulation_data['recording_location'] == 'soma'].drop('recording_location', axis=1)\n",
    "nexus = simulation_data[simulation_data['recording_location'] == 'nexus'].drop('recording_location', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot out the first couple of timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.cm import rainbow  # import a colormap that maps a number to a color\n",
    "plt.style.use('dark_background')\n",
    "N = 200\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "plt.axis('off')\n",
    "\n",
    "for i, row in soma.head(N).iterrows():\n",
    "    plt.plot(\n",
    "        row.index.values.astype(float),  # The indices are strings, so we need to convert them to floats\n",
    "        row.values + i*15,  # plot out the value, plus some offset\n",
    "        zorder=i,  # Setting the correct depth of each trace\n",
    "        c = rainbow(i/len(soma))  # map the index of the trace to a color\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.cm import rainbow  # import a colormap that allows to map a number to a color\n",
    "plt.style.use('dark_background')\n",
    "N = 200\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "plt.axis('off')\n",
    "\n",
    "for i, row in nexus.head(N).iterrows():\n",
    "    plt.plot(\n",
    "        row.index.values.astype(float),\n",
    "        row.values + i*15,\n",
    "        zorder=i,\n",
    "        c = rainbow(i/len(nexus))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
